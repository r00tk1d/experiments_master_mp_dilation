{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain (directional trend) # \n",
    "Every pair of consecutive subsequences in a chain must be connected by both a forward arrow and a backward arrow. The key component of drifting is that the time series must contain chains with clear directionality\n",
    "\n",
    "Stumpy Tutorial Time Series Chains:\n",
    "https://stumpy.readthedocs.io/en/latest/Tutorial_Time_Series_Chains.html\n",
    "\n",
    "Matrix Profile VII: Time Series Chains Calibration Instruction:\n",
    "https://docs.google.com/presentation/d/1-jEynFIkjDR88QFtbHN2Iz8DXY8wMVet/edit#slide=id.p1\n",
    "\n",
    "Robust Time Series Chain Discovery with Incremental Nearest Neighbors:\n",
    "https://sites.google.com/view/robust-time-series-chain-22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.testdata as testdata\n",
    "import core.utils as utils\n",
    "import core.calculate as calculate\n",
    "import core.visualize as visualize\n",
    "import core.results as results\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Robustness without Ranking/anchored with the ground truth starting point (Robustness Paper) ##\n",
    "\n",
    "recall and precision: hits are with overlap > 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "use_case = \"chains\"\n",
    "data_names = ['BME_1', 'BME_2', 'BME_3', 'BME_4', 'BME_5', 'CBF_1', 'CBF_2', 'CBF_3', 'CBF_4', 'CBF_5', 'ChlorineConcentration_1', 'ChlorineConcentration_2', 'ChlorineConcentration_3', 'ChlorineConcentration_4', 'ChlorineConcentration_5', 'ECG200_1', 'ECG200_2', 'ECG200_3', 'ECG200_4', 'ECG200_5', 'ECG5000_1', 'ECG5000_2', 'ECG5000_3', 'ECG5000_4', 'ECG5000_5', 'ECGFiveDays_1', 'ECGFiveDays_2', 'ECGFiveDays_3', 'ECGFiveDays_4', 'ECGFiveDays_5', 'FreezerRegularTrain_1', 'FreezerRegularTrain_2', 'FreezerRegularTrain_3', 'FreezerRegularTrain_4', 'FreezerRegularTrain_5', 'FreezerSmallTrain_1', 'FreezerSmallTrain_2', 'FreezerSmallTrain_3', 'FreezerSmallTrain_4', 'FreezerSmallTrain_5', 'Lightning7_1', 'Lightning7_2', 'Lightning7_3', 'Lightning7_4', 'Lightning7_5', 'Plane_1', 'Plane_2', 'Plane_3', 'Plane_4', 'Plane_5', 'SonyAIBORobotSurface1_1', 'SonyAIBORobotSurface1_2', 'SonyAIBORobotSurface1_3', 'SonyAIBORobotSurface1_4', 'SonyAIBORobotSurface1_5', 'SonyAIBORobotSurface2_1', 'SonyAIBORobotSurface2_2', 'SonyAIBORobotSurface2_3', 'SonyAIBORobotSurface2_4', 'SonyAIBORobotSurface2_5', 'Trace_1', 'Trace_2', 'Trace_3', 'Trace_4', 'Trace_5', 'TwoLeadECG_1', 'TwoLeadECG_2', 'TwoLeadECG_3', 'TwoLeadECG_4', 'TwoLeadECG_5', 'TwoPatterns_1', 'TwoPatterns_2', 'TwoPatterns_3', 'TwoPatterns_4', 'TwoPatterns_5', 'UMD_1', 'UMD_2', 'UMD_3', 'UMD_4', 'UMD_5', 'Wafer_1', 'Wafer_2', 'Wafer_3', 'Wafer_4', 'Wafer_5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dilation = 15\n",
    "starting_offset_gt = 1\n",
    "\n",
    "cols = ['dataname']\n",
    "dilation_sizes = [\"d\"+str(d+1) for d in range(max_dilation)]\n",
    "cols += dilation_sizes\n",
    "\n",
    "recall_table = pd.DataFrame(columns=cols)\n",
    "precision_table = pd.DataFrame(columns=cols)\n",
    "f1_table = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Bulk Experiment\n",
    "for count, data_name in enumerate(data_names):\n",
    "    print(f'Starting Experiment {count+1}/{len(data_names)}: {data_name}')\n",
    "    T = testdata.load_from_mat(\"../data/\" + use_case + \"/robustness/ts/\" + data_name + \".mat\", \"ts\")\n",
    "    l = testdata.load_from_mat(\"../data/\" + use_case + \"/robustness/ts/\" + data_name + \".mat\", \"l\")\n",
    "\n",
    "    ground_truth = testdata.load_gt(\"../data/\" + use_case + \"/robustness/gt/\" + data_name + \".mat\", \"idx_tsc\")\n",
    "\n",
    "    # Hyperparameter\n",
    "    target_w = int(l)\n",
    "    m = None\n",
    "    non_overlapping = False # if True, overlapping chains are filtered\n",
    "    offset = True # if offset=True and offset_value=None, the chains with dilation are calculated with a starting offset of the chain without dilation\n",
    "    offset_value = ground_truth[starting_offset_gt]\n",
    "\n",
    "    # calculate\n",
    "    calculate.chains(T, max_dilation, data_name, use_case, ground_truth, offset, non_overlapping, target_w, m, offset_value=offset_value)\n",
    "\n",
    "    # evaluate\n",
    "    recalls, precisions, f1_scores = utils.get_metrics_for_experiment(max_dilation, data_name, use_case, offset, non_overlapping, target_w, m, ground_truth)\n",
    "    recall_row = [data_name] + recalls\n",
    "    recall_table.loc[len(recall_table)] = recall_row\n",
    "    precision_row = [data_name] + precisions\n",
    "    precision_table.loc[len(precision_table)] = precision_row\n",
    "    f1_row = [data_name] + f1_scores\n",
    "    f1_table.loc[len(f1_table)] = precision_row\n",
    "\n",
    "\n",
    "    # visualize:\n",
    "    # print(f'Ground Truth Chain: {ground_truth}')\n",
    "    # visualize.chains(max_dilation, data_name, use_case, offset, non_overlapping, target_w, m, ground_truth, visualize_chains=False)\n",
    "results.save_stats(recall_table, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_recalls_raw.csv')\n",
    "results.save_stats(precision_table, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_precisions_raw.csv')\n",
    "results.save_stats(f1_table, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_f1_scores_raw.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate raw csv results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'd11',\n",
      "       'd12', 'd13', 'd14', 'd15'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46868/968576564.py:21: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  recalls_df = recalls_df.append(recalls_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  recalls_df = recalls_df.append(recalls_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:22: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  precisions_df = precisions_df.append(precisions_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  precisions_df = precisions_df.append(precisions_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:23: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  f1_scores_df = f1_scores_df.append(f1_scores_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  f1_scores_df = f1_scores_df.append(f1_scores_df_raw[i:i+5].mean(), ignore_index=True)\n",
      "/tmp/ipykernel_46868/968576564.py:31: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  averages = df.mean()\n",
      "/tmp/ipykernel_46868/968576564.py:31: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  averages = df.mean()\n",
      "/tmp/ipykernel_46868/968576564.py:31: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  averages = df.mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "starting_strings = [name.split('_')[0] for name in data_names]\n",
    "data_names_condensed = list(set(starting_strings))\n",
    "\n",
    "recalls_df_raw = pd.read_csv(f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_recalls_raw.csv')\n",
    "precisions_df_raw = pd.read_csv(f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_precisions_raw.csv')\n",
    "f1_scores_df_raw = pd.read_csv(f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_f1_scores_raw.csv')\n",
    "\n",
    "recalls_df = pd.DataFrame(columns=recalls_df_raw.columns[1:])\n",
    "precisions_df = pd.DataFrame(columns=precisions_df_raw.columns[1:])\n",
    "f1_scores_df = pd.DataFrame(columns=f1_scores_df_raw.columns[1:])\n",
    "\n",
    "# build average performance for each dataset\n",
    "for i in range(0, len(recalls_df_raw), 5):\n",
    "    recalls_df = recalls_df.append(recalls_df_raw[i:i+5].mean(), ignore_index=True)\n",
    "    precisions_df = precisions_df.append(precisions_df_raw[i:i+5].mean(), ignore_index=True)\n",
    "    f1_scores_df = f1_scores_df.append(f1_scores_df_raw[i:i+5].mean(), ignore_index=True)\n",
    "\n",
    "recalls_df.insert(0, 'data_names', data_names_condensed)\n",
    "precisions_df.insert(0, 'data_names', data_names_condensed)\n",
    "f1_scores_df.insert(0, 'data_names', data_names_condensed)\n",
    "\n",
    "def add_av_performance_row(df):\n",
    "    averages = df.mean()\n",
    "    average_row = [\"AVERAGE PERFORMANCE\"] + averages.values.tolist()\n",
    "    df.loc[len(df)] = average_row\n",
    "    return df\n",
    "\n",
    "def add_wins_ties_row(df):\n",
    "    ties = [0] * (len(df.columns) - 1)\n",
    "    wins = [0] * (len(df.columns) - 1)\n",
    "    for index, row in df.iterrows():\n",
    "        # get maximum value in row\n",
    "        max_value = max(row[1:])\n",
    "        max_indices = [index - 1 for index, value in enumerate(row) if value == max_value]\n",
    "\n",
    "        if len(max_indices) == 1:\n",
    "            wins[max_indices[0]] += 1\n",
    "        else:\n",
    "            for i in max_indices:\n",
    "                ties[i] += 1\n",
    "\n",
    "    df.loc[len(df)] = [\"WINS\"] + wins\n",
    "    df.loc[len(df)] = [\"TIES\"] + ties\n",
    "    return df\n",
    "\n",
    "recalls_df = add_av_performance_row(recalls_df)\n",
    "recalls_df = add_wins_ties_row(recalls_df)\n",
    "precisions_df = add_av_performance_row(precisions_df)\n",
    "precisions_df = add_wins_ties_row(precisions_df)\n",
    "f1_scores_df = add_av_performance_row(f1_scores_df)\n",
    "f1_scores_df = add_wins_ties_row(f1_scores_df)\n",
    "\n",
    "# save results\n",
    "results.save_stats(recalls_df, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_recalls.csv')\n",
    "results.save_stats(precisions_df, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_precisions.csv')\n",
    "results.save_stats(f1_scores_df, f'../results/chains/robustness_without_ranking_anchoredgt{starting_offset_gt}_f1_scores.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63f775a29077d88326ae6f063688ea24fd4744bb6810a004c04d9663ba131b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
