{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation (regimes) with arc curves # \n",
    "“arc curve” annotates the raw time series with information about the likelihood of a regime change.\n",
    "\n",
    "https://stumpy.readthedocs.io/en/latest/Tutorial_Semantic_Segmentation.html\n",
    "\n",
    "https://sites.google.com/site/onlinesemanticsegmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "from tssb.utils import load_time_series_segmentation_datasets\n",
    "from tssb.evaluation import covering\n",
    "import pandas as pd\n",
    "import stumpy\n",
    "\n",
    "import core.utils as utils\n",
    "import core.calculate as calculate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tssb.utils import visualize_time_series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Segmentation Benchmark (TSSB) ##\n",
    "\n",
    "https://github.com/ermshaua/time-series-segmentation-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tssb = load_time_series_segmentation_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_fluss_known_cps(T, T_name, cps, ds, L, n_regimes, target_w, m):\n",
    "    assert (target_w is None) != (m is None)\n",
    "    if target_w:\n",
    "        calculate_m = True\n",
    "    else:\n",
    "        calculate_m = False\n",
    "    \n",
    "    current_best_dilation = None\n",
    "    sum_current_best_cac_score = 99\n",
    "    for d in ds:\n",
    "        if calculate_m:\n",
    "            m = round((target_w-1)/d) + 1\n",
    "        actual_w = (m-1)*d + 1\n",
    "\n",
    "        if d == 1:\n",
    "            mp = stumpy.stump(T, m=m)\n",
    "        else:\n",
    "            mp = stumpy.stump_dil(T, m=m, d=d)\n",
    "        cac, found_cps = stumpy.fluss(mp[:, 1], L=L, n_regimes=n_regimes)\n",
    "        sum_cac_score = sum([cac[cp] for cp in found_cps])\n",
    "        if sum_cac_score < sum_current_best_cac_score:\n",
    "            current_best_dilation = d\n",
    "            sum_current_best_cac_score = sum_cac_score\n",
    "            score = covering({0: cps}, found_cps, T.shape[0])\n",
    "    print(f\"Time Series: {T_name}, Learned Dilation size: {current_best_dilation}, Score: {score}\")\n",
    "    return score, current_best_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series: Adiac, Learned Dilation size: 4, Score: 0.8736568918880732\n",
      "Time Series: ArrowHead, Learned Dilation size: 4, Score: 0.985496930254549\n",
      "Time Series: Beef, Learned Dilation size: 4, Score: 0.7127727768685216\n",
      "Time Series: BeetleFly, Learned Dilation size: 5, Score: 0.9692234848484848\n",
      "Time Series: BirdChicken, Learned Dilation size: 3, Score: 0.9806558309386972\n",
      "Time Series: Car, Learned Dilation size: 2, Score: 0.7364715422298941\n",
      "Time Series: CBF, Learned Dilation size: 3, Score: 0.6867847481802085\n",
      "Time Series: Chinatown, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: ChlorineConcentration, Learned Dilation size: 1, Score: 0.9997436461895858\n",
      "Time Series: CinCECGTorso, Learned Dilation size: 5, Score: 0.6076885270406197\n",
      "Time Series: Coffee, Learned Dilation size: 2, Score: 0.9880711462450592\n",
      "Time Series: Computers, Learned Dilation size: 1, Score: 0.4935159817351598\n",
      "Time Series: CricketX, Learned Dilation size: 1, Score: 0.7874002518254477\n",
      "Time Series: CricketY, Learned Dilation size: 2, Score: 0.3966336259672689\n",
      "Time Series: CricketZ, Learned Dilation size: 1, Score: 0.733173365992264\n",
      "Time Series: Crop, Learned Dilation size: 2, Score: 0.24307392714688997\n",
      "Time Series: DiatomSizeReduction, Learned Dilation size: 5, Score: 0.9403415520269792\n",
      "Time Series: DistalPhalanxOutlineAgeGroup, Learned Dilation size: 1, Score: 0.9342348653044749\n",
      "Time Series: DistalPhalanxTW, Learned Dilation size: 3, Score: 0.6699599887552614\n",
      "Time Series: DodgerLoopDay, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: ECG200, Learned Dilation size: 2, Score: 0.9565181880241858\n",
      "Time Series: ECGFiveDays, Learned Dilation size: 1, Score: 0.9698885296530424\n",
      "Time Series: EOGHorizontalSignal, Learned Dilation size: 4, Score: 0.4129983292936706\n",
      "Time Series: EOGVerticalSignal, Learned Dilation size: 4, Score: 0.3353190881212357\n",
      "Time Series: FaceAll, Learned Dilation size: 1, Score: 0.39921707302188714\n",
      "Time Series: FaceFour, Learned Dilation size: 3, Score: 0.5379045034361126\n",
      "Time Series: FacesUCR, Learned Dilation size: 2, Score: 0.6682686192481564\n",
      "Time Series: FiftyWords, Learned Dilation size: 4, Score: 0.5684677548216591\n",
      "Time Series: Fish, Learned Dilation size: 2, Score: 0.42888413306351697\n",
      "Time Series: FreezerRegularTrain, Learned Dilation size: 4, Score: 0.4569765675640828\n",
      "Time Series: Ham, Learned Dilation size: 1, Score: 0.25052892163833657\n",
      "Time Series: Herring, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: GunPoint, Learned Dilation size: 2, Score: 0.987277811550152\n",
      "Time Series: Haptics, Learned Dilation size: 4, Score: 0.40016826015949586\n",
      "Time Series: InlineSkate, Learned Dilation size: 5, Score: 0.5818596453747468\n",
      "Time Series: InsectWingbeatSound, Learned Dilation size: 1, Score: 0.6899781354846006\n",
      "Time Series: ItalyPowerDemand, Learned Dilation size: 2, Score: 0.9526307990732259\n",
      "Time Series: LargeKitchenAppliances, Learned Dilation size: 2, Score: 0.6192776370027349\n",
      "Time Series: Lightning2, Learned Dilation size: 4, Score: 0.9203026969165353\n",
      "Time Series: Lightning7, Learned Dilation size: 4, Score: 0.5804897626202865\n",
      "Time Series: Mallat, Learned Dilation size: 4, Score: 0.5651370676487341\n",
      "Time Series: Meat, Learned Dilation size: 3, Score: 0.981154461502538\n",
      "Time Series: MedicalImages, Learned Dilation size: 5, Score: 0.9895298496918091\n",
      "Time Series: MelbournePedestrian, Learned Dilation size: 2, Score: 0.39908849026426635\n",
      "Time Series: MiddlePhalanxOutlineAgeGroup, Learned Dilation size: 3, Score: 0.5835538095541752\n",
      "Time Series: MiddlePhalanxOutlineCorrect, Learned Dilation size: 3, Score: 0.6153401764628507\n",
      "Time Series: MiddlePhalanxTW, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: MoteStrain, Learned Dilation size: 5, Score: 0.9591666666666667\n",
      "Time Series: NonInvasiveFetalECGThorax1, Learned Dilation size: 5, Score: 0.33653102485584124\n",
      "Time Series: NonInvasiveFetalECGThorax2, Learned Dilation size: 5, Score: 0.4131279411359761\n",
      "Time Series: OliveOil, Learned Dilation size: 5, Score: 0.976546707606273\n",
      "Time Series: OSULeaf, Learned Dilation size: 1, Score: 0.7185625122541011\n",
      "Time Series: Plane, Learned Dilation size: 4, Score: 0.7965002181854286\n",
      "Time Series: ProximalPhalanxOutlineAgeGroup, Learned Dilation size: 1, Score: 0.6797065737919025\n",
      "Time Series: ProximalPhalanxOutlineCorrect, Learned Dilation size: 1, Score: 0.5485783163238369\n",
      "Time Series: ProximalPhalanxTW, Learned Dilation size: 2, Score: 0.49957629238465806\n",
      "Time Series: ShapesAll, Learned Dilation size: 5, Score: 0.39052249203821654\n",
      "Time Series: ShapeletSim, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: SonyAIBORobotSurface1, Learned Dilation size: 5, Score: 0.4178731343283582\n",
      "Time Series: SonyAIBORobotSurface2, Learned Dilation size: 2, Score: 0.9751884580509816\n",
      "Time Series: Strawberry, Learned Dilation size: 1, Score: 0.4707435290020697\n",
      "Time Series: SwedishLeaf, Learned Dilation size: 2, Score: 0.5055392170676908\n",
      "Time Series: Symbols, Learned Dilation size: 5, Score: 0.7953624161139358\n",
      "Time Series: SyntheticControl, Learned Dilation size: 2, Score: 0.77074580777022\n",
      "Time Series: ToeSegmentation1, Learned Dilation size: 2, Score: 0.9913729523553566\n",
      "Time Series: ToeSegmentation2, Learned Dilation size: 5, Score: 0.9852034359431503\n",
      "Time Series: Trace, Learned Dilation size: 2, Score: 0.6433361730878282\n",
      "Time Series: TwoLeadECG, Learned Dilation size: 3, Score: 0.46777426602343614\n",
      "Time Series: UMD, Learned Dilation size: 1, Score: 1.0\n",
      "Time Series: UWaveGestureLibraryAll, Learned Dilation size: 1, Score: 0.5855202253536799\n",
      "Time Series: UWaveGestureLibraryX, Learned Dilation size: 1, Score: 0.3942514610134796\n",
      "Time Series: UWaveGestureLibraryY, Learned Dilation size: 1, Score: 0.5879965193353933\n",
      "Time Series: UWaveGestureLibraryZ, Learned Dilation size: 1, Score: 0.6016321467081485\n",
      "Time Series: WordSynonyms, Learned Dilation size: 1, Score: 0.8190996867328404\n",
      "Time Series: Yoga, Learned Dilation size: 4, Score: 0.996126904759683\n"
     ]
    }
   ],
   "source": [
    "dilation_sizes = [1,2,3,4,5]\n",
    "\n",
    "col_names = [\"flussEnsemble\", \"dilationSize\"]\n",
    "df_my_results = pd.DataFrame(columns=col_names)\n",
    "for _, (ts_name, window_size, cps, ts) in tssb.iterrows():\n",
    "    L = window_size\n",
    "    n_regimes = len(cps)+1\n",
    "    score, current_best_dilation = segmentation_fluss_known_cps(ts, ts_name, cps, dilation_sizes, L, n_regimes, target_w=None, m=window_size)\n",
    "    df_my_results.loc[len(df_my_results)] = [score, current_best_dilation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both dataframes\n",
    "df_scores = pd.read_csv(\"../results/segmentation/segmentation_covering_known_stumpy_m_ensemble.csv\")\n",
    "result = pd.concat([df_scores, df_my_results], axis=1)\n",
    "result.to_csv(\"../results/segmentation/segmentation_covering_known_stumpy_m_ensemble_learned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63f775a29077d88326ae6f063688ea24fd4744bb6810a004c04d9663ba131b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
